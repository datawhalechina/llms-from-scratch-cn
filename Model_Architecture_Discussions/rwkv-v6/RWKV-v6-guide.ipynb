{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f64be1c0-02a8-4ea9-ae05-85b66e803cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "# The RWKV Language Model - https://github.com/BlinkDL/RWKV-LM\n",
    "########################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=200)\n",
    "import types, torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "MyModule = torch.jit.ScriptModule\n",
    "MyFunction = torch.jit.script_method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f7fb18-23e7-44a1-883e-0bd673b8fb0b",
   "metadata": {},
   "source": [
    "![](./img/01.png)\n",
    "\n",
    "Âõæ1ÔºöRWKVÊû∂ÊûÑÊ¶ÇËø∞„ÄÇÂ∑¶‰æßÔºöÊó∂Èó¥Ê∑∑ÂêàÂíåÈÄöÈÅìÊ∑∑ÂêàÂùóÔºõÂè≥‰∏äËßíÔºö‰Ωú‰∏∫RNNÂçïÂÖÉÁöÑRWKVÊó∂Èó¥Ê∑∑ÂêàÂùóÔºõ‰∏≠‰∏ãÈÉ®ÔºöÂâçÈ¶àÊ®°Âùó‰∏≠ÁöÑ‰ª§ÁâåÁßª‰ΩçÊ®°ÂùóÂíåEagleÊó∂Èó¥Ê∑∑ÂêàÔºõÂè≥‰∏ãËßíÔºöFinchÊó∂Èó¥Ê∑∑Âêà‰∏≠ÁöÑ‰ª§ÁâåÁßª‰ΩçÊ®°Âùó„ÄÇÊâÄÊúâÂΩ¢Áä∂Ê≥®Èáä‰∏∫ÁÆÄÊ¥ÅËµ∑ËßÅÂÅáËÆæ‰∏∫ÂçïÂ§¥„ÄÇËôöÁ∫øÁÆ≠Â§¥ÔºàÂ∑¶‰æßÔºåÂè≥‰∏äËßíÔºâË°®Á§∫Âú®Finch‰∏≠ÊúâËøûÊé•Ôºå‰ΩÜÂú®Eagle‰∏≠Ê≤°Êúâ„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d66b1f-5c04-44d7-9bbc-76f844707327",
   "metadata": {},
   "source": [
    "È¶ñÂÖàRWKV 6Áõ∏ÊØî‰∫éRWKV 5Âú®Token Shift‰∏äËøõË°å‰∫ÜÊîπËøõÔºåÂÖ∑‰ΩìÁúã‰∏ãÈù¢ÁöÑ‰∏≠Èó¥Â∫ïÈÉ®ÂíåÂè≥‰∏ãËßíÁöÑÂõæÔºåÂàÜÂà´ÊòØRWKV 4/5ÁöÑToken ShiftÊñπÂºèÂíåRWKV 6ÁöÑToken ShiftÊñπÂºè„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cd8fa2-c1a4-4fdc-ba5d-858b25df1bcf",
   "metadata": {},
   "source": [
    "ÂÖ∑‰ΩìÂÜÖÂÆπÂ¶Ç‰∏ãÔºö\n",
    "\n",
    "### ÂÖ¨ÂºèÈÉ®ÂàÜ\n",
    "\n",
    "Finch Token Shift‰∏≠‰ΩøÁî®ÁöÑÊï∞ÊçÆ‰æùËµñÁ∫øÊÄßÊèíÂÄºÔºàddlerpÔºâÂÆö‰πâÂ¶Ç‰∏ãÔºö\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{lora}_{\\Box}(x) &= \\lambda_{\\Box} + \\tanh(x A_{\\Box}) B_{\\Box} \\tag{14} \\\\\n",
    "\\text{ddlerp}_{\\Box}(a, b) &= a + (b - a) \\odot \\text{lora}_{\\Box}(a + (b - a) \\odot \\mu_{x}) \\tag{15}\n",
    "\\end{align*}\n",
    "\n",
    "### Ëß£ÈáäÈÉ®ÂàÜ\n",
    "\n",
    "- **ÂèØÂ≠¶‰π†ÂêëÈáèÂíåÁü©Èòµ**Ôºö\n",
    "  - $\\mu_{x}$ ÂíåÊØè‰∏™ $\\lambda_{\\Box}$ ÂºïÂÖ•‰∫ÜÁª¥Â∫¶‰∏∫ $D$ ÁöÑÂèØËÆ≠ÁªÉÂêëÈáè„ÄÇ\n",
    "  - $A_{\\Box} \\in \\mathbb{R}^{D \\times 32}$ Âíå $B_{\\Box} \\in \\mathbb{R}^{32 \\times D}$ ÂºïÂÖ•‰∫ÜÊñ∞ÁöÑÂèØËÆ≠ÁªÉÊùÉÈáçÁü©Èòµ„ÄÇ\n",
    "  - ÂØπ‰∫éÂÖ¨Âºè‰∏≠ÊèêÂà∞ÁöÑLoRA$_{\\omega}$ÁöÑÁâπÊÆäÊÉÖÂÜµÔºåÂºïÂÖ•‰∫ÜÂèåÂÄçÂ§ßÂ∞èÁöÑÂèØËÆ≠ÁªÉÊùÉÈáçÁü©ÈòµÔºö$A_{\\omega} \\in \\mathbb{R}^{D \\times 64}$ Âíå $B_{\\omega} \\in \\mathbb{R}^{64 \\times D}$„ÄÇ\n",
    "\n",
    "- **Êú™Êù•Ê®°ÂûãÊâ©Â±ï**Ôºö\n",
    "  - Âõæ1‰∏≠Âè≥‰∏ãËßíÊòæÁ§∫‰∫Ü‰∏Ä‰∏™Á§∫ÊÑèÂõæ„ÄÇ\n",
    "  - Êú™Êù•7BÂèäÊõ¥Â§ßËßÑÊ®°ÁöÑFinchÊ®°ÂûãÈ¢ÑËÆ°Â∞ÜËøõ‰∏ÄÊ≠•Â¢ûÂä†Ëøô‰∫õÊùÉÈáçÁü©ÈòµÁöÑÂ§ßÂ∞èÔºàÂèØËÉΩÁøªÂÄçÊàñÊõ¥Â§öÔºâ„ÄÇ\n",
    "\n",
    "### ÂäüËÉΩ‰∏é‰ΩúÁî®\n",
    "\n",
    "ËøôÁßçÂ∏¶ÊúâÊï∞ÊçÆ‰æùËµñÊÄßÁöÑToken ShiftÊñ∞ÂΩ¢ÂºèÊó®Âú®Êâ©Â±ïÊ®°ÂûãË∂ÖË∂äRWKV-4/EagleÈ£éÊ†ºÁöÑToken ShiftÁöÑËÉΩÂäõÔºå‰ΩøÂæóÊØè‰∏™ÈÄöÈÅìÂàÜÈÖçÁöÑÊñ∞ÊóßÊï∞ÊçÆÈáèÁé∞Âú®‰æùËµñ‰∫éÂΩìÂâçÂíåÂâç‰∏Ä‰∏™Êó∂Èó¥Ê≠•ÁöÑËæìÂÖ•„ÄÇ\n",
    "\n",
    "### ËØ¶ÁªÜËß£Èáä\n",
    "\n",
    "- **Êï∞ÊçÆ‰æùËµñÁ∫øÊÄßÊèíÂÄºÔºàddlerpÔºâ**Ôºö\n",
    "  - ddlerpÈÄöËøáÂÖ¨Âºè14ÂíåÂÖ¨Âºè15ÂÆûÁé∞ÔºåÂÆÉÁªìÂêà‰∫ÜÂΩìÂâçÊó∂Èó¥Ê≠•ÂíåÂâç‰∏Ä‰∏™Êó∂Èó¥Ê≠•ÁöÑ‰ø°ÊÅØÊù•ËÆ°ÁÆóÊèíÂÄº„ÄÇ\n",
    "  - $\\text{lora}_{\\Box}(x)$Âà©Áî®‰∫Ü‰∏Ä‰∏™$\\lambda_{\\Box}$ÂêëÈáèÂíåÈÄöËøá$\\tanh$ÂáΩÊï∞Â§ÑÁêÜÁöÑ$x A_{\\Box}$‰∏é$B_{\\Box}$ÁöÑ‰πòÁßØÊù•ÁîüÊàê„ÄÇ\n",
    "\n",
    "- **Ê®°ÂûãËÉΩÂäõÊâ©Â±ï**Ôºö\n",
    "  - ÈÄöËøáËøôÁßçÊï∞ÊçÆ‰æùËµñÁöÑToken ShiftÔºåFinchÊ®°ÂûãËÉΩÂ§üÊõ¥ÁÅµÊ¥ªÂú∞Â§ÑÁêÜÊó∂Èó¥Ê≠•‰πãÈó¥ÁöÑ‰ø°ÊÅØ‰º†ÈÄíÔºå‰ΩøÂæóÊ®°ÂûãÂú®Â§ÑÁêÜÂ§çÊùÇÂ∫èÂàóÊï∞ÊçÆÊó∂Êõ¥Âä†Á≤æÁ°ÆÂíåÈ´òÊïà„ÄÇ\n",
    "\n",
    "ÊÄªÁªìÊù•ËØ¥ÔºåFinchÂú®Token Shift‰∏äÂºïÂÖ•‰∫ÜÊï∞ÊçÆ‰æùËµñÁöÑÁ∫øÊÄßÊèíÂÄºÔºåÂà©Áî®ÂèØËÆ≠ÁªÉÁöÑÂêëÈáèÂíåÁü©ÈòµÊù•Â¢ûÂº∫Ê®°ÂûãÁöÑÁÅµÊ¥ªÊÄßÂíåËÉΩÂäõÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞Â§ÑÁêÜÊó∂Èó¥Ê≠•‰πãÈó¥ÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÊï¥‰ΩìÊÄßËÉΩ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1261d4e1-df4e-410b-a4fa-45452c4b6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RWKV_TOKENIZER():\n",
    "    table: list[list[list[bytes]]]\n",
    "    good: list[set[int]]\n",
    "    wlen: list[int]\n",
    "    def __init__(self, file_name):\n",
    "        self.idx2token = {}\n",
    "        sorted = [] # must be already sorted\n",
    "        lines = open(file_name, \"r\", encoding=\"utf-8\").readlines()\n",
    "        for l in lines:\n",
    "            idx = int(l[:l.index(' ')])\n",
    "            x = eval(l[l.index(' '):l.rindex(' ')])\n",
    "            x = x.encode(\"utf-8\") if isinstance(x, str) else x\n",
    "            assert isinstance(x, bytes)\n",
    "            assert len(x) == int(l[l.rindex(' '):])\n",
    "            sorted += [x]\n",
    "            self.idx2token[idx] = x\n",
    "\n",
    "        self.token2idx = {}\n",
    "        for k, v in self.idx2token.items():\n",
    "            self.token2idx[v] = int(k)\n",
    "\n",
    "        # precompute some tables for fast matching\n",
    "        self.table = [[[] for j in range(256)] for i in range(256)]\n",
    "        self.good = [set() for i in range(256)]\n",
    "        self.wlen = [0 for i in range(256)]\n",
    "\n",
    "        for i in reversed(range(len(sorted))): # reverse order - match longer tokens first\n",
    "            s = sorted[i]\n",
    "            if len(s) >= 2:\n",
    "                s0 = int(s[0])\n",
    "                s1 = int(s[1])\n",
    "                self.table[s0][s1] += [s]\n",
    "                self.wlen[s0] = max(self.wlen[s0], len(s))\n",
    "                self.good[s0].add(s1)\n",
    "\n",
    "    def encodeBytes(self, src: bytes) -> list[int]:\n",
    "        src_len: int = len(src)\n",
    "        tokens: list[int] = []\n",
    "        i: int = 0\n",
    "        while i < src_len:\n",
    "            s: bytes = src[i : i + 1]\n",
    "\n",
    "            if i < src_len - 1:\n",
    "                s1: int = int(src[i + 1])\n",
    "                s0: int = int(src[i])\n",
    "                if s1 in self.good[s0]:\n",
    "                    sss: bytes = src[i : i + self.wlen[s0]]\n",
    "                    try:\n",
    "                        s = next(filter(sss.startswith, self.table[s0][s1]))\n",
    "                    except:\n",
    "                        pass\n",
    "            tokens.append(self.token2idx[s])\n",
    "            i += len(s)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def decodeBytes(self, tokens):\n",
    "        return b''.join(map(lambda i: self.idx2token[i], tokens))\n",
    "\n",
    "    def encode(self, src: str):\n",
    "        return self.encodeBytes(src.encode(\"utf-8\"))\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return self.decodeBytes(tokens).decode('utf-8')\n",
    "\n",
    "    def printTokens(self, tokens):\n",
    "        for i in tokens:\n",
    "            s = self.idx2token[i]\n",
    "            try:\n",
    "                s = s.decode('utf-8')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'{repr(s)}{i}', end=' ')\n",
    "            # print(repr(s), i)\n",
    "        print()\n",
    "\n",
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725bc55e-7f3f-4c1c-9664-ad84bf68e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÈááÊ†∑ÊñπÂºèÊ≤°ÊúâÂèòÂåñ\n",
    "def sample_logits(out, temperature=1.0, top_p=0.8):\n",
    "    probs = F.softmax(out, dim=-1).numpy()\n",
    "    sorted_probs = np.sort(probs)[::-1]\n",
    "    cumulative_probs = np.cumsum(sorted_probs)\n",
    "    cutoff = float(sorted_probs[np.argmax(cumulative_probs > top_p)])\n",
    "    probs[probs < cutoff] = 0\n",
    "    if temperature != 1.0:\n",
    "        probs = probs.pow(1.0 / temperature)\n",
    "    probs = probs / np.sum(probs)\n",
    "    out = np.random.choice(a=len(probs), p=probs)\n",
    "    return out\n",
    "\n",
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "raw",
   "id": "812fac97-a6b8-423c-831d-fe7397883437",
   "metadata": {},
   "source": [
    "Ê®°Âûã‰∏ãËΩΩÂú∞ÂùÄÔºöhttps://hf-mirror.com/BlinkDL/rwkv-6-world/resolve/main/RWKV-x060-World-1B6-v2.1-20240328-ctx4096.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "434ff88e-b94e-4f8b-86a3-7fefca32cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RWKV_TOKENIZER(\"./rwkv_vocab_v20230424.txt\")\n",
    "\n",
    "args = types.SimpleNamespace()\n",
    "args.MODEL_NAME = '/data1/ckw/RWKV-x060-World-1B6-v2.1-20240328-ctx4096'\n",
    "args.n_layer = 24\n",
    "args.n_embd = 2048\n",
    "args.vocab_size = 65536\n",
    "\n",
    "context = \"\\nDatawhale is \"\n",
    "# context = \"\\nÊàë‰ª¨ÂèëÁé∞\"\n",
    "NUM_TRIALS = 3\n",
    "LENGTH_PER_TRIAL = 100\n",
    "TEMPERATURE = 1.0\n",
    "TOP_P = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee395717-e599-40fd-a4b9-ddfc800babea",
   "metadata": {},
   "source": [
    "Áõ∏ÊØî‰∫éRWKV 5ÁöÑChannel MixingÔºàËßÅ‰∏ãÈù¢‰ª£Á†ÅÔºâÊù•ËØ¥ÔºåRWKV6ÁöÑChannel MixingÊ≤°ÊúâÂèòÂåñÔºåËøôÈáåÁöÑ`time_maa_k`ÂíåRWKV 5‰∏≠ÁöÑ`time_mix_k`ÊòØÁõ∏ÂêåÂΩ¢Áä∂ÁöÑÂèØÂ≠¶‰π†ÂèÇÊï∞ÔºåÈÉΩÊòØ‰∏Ä‰∏™Áª¥Â∫¶‰∏∫DÔºàÊ®°ÂûãÁöÑÈöêËóèÂ±ÇÁª¥Â∫¶ÔºâÁöÑÂº†Èáè„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54571fa3-52c6-4b05-ab97-9f06d76a522e",
   "metadata": {},
   "source": [
    "FinchÂú®Êó∂Èó¥Ê∑∑ÂêàÔºàTime MixingÔºâ‰∏äÂÅö‰∫Ü‰ª•‰∏ãÊîπËøõÔºåÂÖ∑‰ΩìÂÜÖÂÆπÂ¶Ç‰∏ãÔºö\n",
    "\n",
    "### ÂÖ¨ÂºèÈÉ®ÂàÜ\n",
    "\n",
    "FinchÊó∂Èó¥Ê∑∑ÂêàÁöÑÂÖ¨ÂºèÂ¶Ç‰∏ãÔºö\n",
    "\n",
    "\\begin{align*}\n",
    "\\Box_t &= \\text{lerp}_{\\Box}(x_t, x_{t-1}) W_{\\Box}, \\quad \\Box \\in \\{r, k, v, g\\} \\tag{16} \\\\\n",
    "d_t &= \\text{lora}_d(\\text{ddlerp}_d(x_t, x_{t-1})) \\tag{17} \\\\\n",
    "w_t &= \\exp(-\\exp(d_t)) \\tag{18} \\\\\n",
    "\\text{wk} \\mathbf{v}_t &= \\text{diag}(u) \\cdot k_t^\\top \\cdot v_t + \\sum_{i=1}^{t-1} \\left( \\prod_{j=1}^{i-1} w_j \\right) \\cdot k_i^\\top \\cdot v_i \\in \\mathbb{R}^{(D/h) \\times (D/h)} \\tag{19} \\\\\n",
    "o_t &= \\text{concat} \\left( \\text{SiLU}(g_t) \\odot \\text{LayerNorm}(r_t \\cdot \\text{wk} \\mathbf{v}_t) \\right) W_o \\in \\mathbb{R}^D \\tag{20}\n",
    "\\end{align*}\n",
    "\n",
    "### Ëß£ÈáäÈÉ®ÂàÜ\n",
    "\n",
    "- **ÂèØÂ≠¶‰π†ÂêëÈáèÂíåÁü©Èòµ**Ôºö\n",
    "  - $\\Box_t$ ÊòØÈÄöËøáÁ∫øÊÄßÊèíÂÄºÔºàlerpÔºâËÆ°ÁÆóÂæóÂà∞ÁöÑÔºåÈÄÇÁî®‰∫éÊé•ÂèóÂ∫¶ÔºàreceptanceÔºâ„ÄÅÈîÆÔºàkeyÔºâ„ÄÅÂÄºÔºàvalueÔºâÂíåÈó®ÊéßÂêëÈáèÔºàgate vectorsÔºâ„ÄÇ\n",
    "  - $d_t$ ÊòØÈÄöËøá $\\text{lora}_d$ ÂáΩÊï∞ÂØπ $\\text{ddlerp}_d(x_t, x_{t-1})$ ËøõË°åÂ§ÑÁêÜÂæóÂà∞ÁöÑ„ÄÇ\n",
    "  - $w_t$ ÊòØÁî± $d_t$ ËÆ°ÁÆóÂæóÂà∞ÁöÑÔºåÁî®‰∫éÊéßÂà∂Ë°∞ÂáèÁöÑÂä®ÊÄÅÂèòÂåñ„ÄÇ\n",
    "\n",
    "- **Êó∂Èó¥Ê∑∑ÂêàËÆ°ÁÆó**Ôºö\n",
    "  - $\\text{wk} \\mathbf{v}_t$ ÊòØÈÄöËøáÂΩìÂâçÈîÆÂÄºÂØπ $k_t^\\top \\cdot v_t$ ÂíåÊâÄÊúâ‰πãÂâçÊó∂Èó¥Ê≠•ÁöÑÈîÆÂÄºÂØπ $k_i^\\top \\cdot v_i$ ÁöÑÂä†ÊùÉÂíåËÆ°ÁÆóÂæóÂà∞ÁöÑÔºåÊùÉÈáçÁî± $w_t$ ÊéßÂà∂„ÄÇ\n",
    "  - ËæìÂá∫ $o_t$ ÊòØÈÄöËøáËøûÊé•ÔºàconcatÔºâ $\\text{SiLU}(g_t)$ Âíå $\\text{LayerNorm}(r_t \\cdot \\text{wk} \\mathbf{v}_t)$ ÁöÑÁªìÊûúÂæóÂà∞ÁöÑ„ÄÇ\n",
    "\n",
    "- **ÈÄíÂΩíÂΩ¢Âºè**Ôºö\n",
    "  \\begin{align*}\n",
    "  \\text{wk} \\mathbf{v}' &= s + \\text{diag}(u) \\cdot k^\\top \\cdot v \\tag{21} \\\\\n",
    "  s' &= \\text{diag}(w) \\cdot s + k^\\top \\cdot v \\tag{22}\n",
    "  \\end{align*}\n",
    "\n",
    "### ÂäüËÉΩ‰∏é‰ΩúÁî®\n",
    "\n",
    "‰∏éEagle‰∏çÂêåÔºåFinch‰∏≠ÁöÑ $w_t$ ‰∏çÊòØÂú®Êï¥‰∏™Â∫èÂàó‰∏≠Âõ∫ÂÆöÁöÑ„ÄÇÊØè‰∏™ÈÄöÈÅìÁöÑ $w_t$ ÂèØ‰ª•ÈöèÊó∂Èó¥Âä®ÊÄÅÂèòÂåñÔºåÂÖ∑‰ΩìÂèñÂÜ≥‰∫éÊï∞ÊçÆËæìÂÖ•ÔºåËøô‰πüÊòØFinch‰∏≠Ë°∞ÂáèÁöÑÊ†∏ÂøÉÂèòÂåñ„ÄÇ\n",
    "\n",
    "### ËØ¶ÁªÜËß£Èáä\n",
    "\n",
    "- **Âä®ÊÄÅË°∞Âáè**Ôºö\n",
    "  - FinchÂºïÂÖ•ÁöÑÊï∞ÊçÆ‰æùËµñË°∞Âáè‰ΩøÂæóÊØè‰∏™ÈÄöÈÅìÁöÑ $w_t$ ÂèØ‰ª•Ê†πÊçÆÂΩìÂâçÂíå‰πãÂâçÁöÑËæìÂÖ•Âä®ÊÄÅÂèòÂåñÔºåËÄå‰∏çÊòØÂõ∫ÂÆöÁöÑÂ≠¶‰π†ÂêëÈáè„ÄÇ\n",
    "  - ËøôÁßçÂä®ÊÄÅË°∞ÂáèÊú∫Âà∂ÈÄöËøáÊñ∞ÁöÑLoRAÊú∫Âà∂Â∫îÁî®Âà∞Â≠¶‰π†ÂêëÈáè‰∏äÔºåÂ¢ûÂä†‰∫ÜÊ®°ÂûãÁöÑÁÅµÊ¥ªÊÄß„ÄÇ\n",
    "\n",
    "- **È´òÁ∫ßToken-Shift**Ôºö\n",
    "  - Êñ∞ÁöÑÊó∂Èó¥Ë°∞Âáè $w_t$ Ëøõ‰∏ÄÊ≠•Â∫îÁî®‰∫ÜLoRAÊú∫Âà∂ÔºåÂÖÅËÆ∏ÊØè‰∏™ÈÄöÈÅìÁöÑ $w_t$ Âü∫‰∫éÂΩìÂâçÂíå‰πãÂâçÁöÑ‰ª§ÁâåÊ∑∑ÂêàÊù•ÂèòÂåñ„ÄÇ\n",
    "\n",
    "ÊÄªÁªìÊù•ËØ¥ÔºåFinchÂú®Êó∂Èó¥Ê∑∑Âêà‰∏äÈÄöËøáÂºïÂÖ•Êï∞ÊçÆ‰æùËµñÁöÑÂä®ÊÄÅË°∞ÂáèÊú∫Âà∂ÂíåÈ´òÁ∫ßToken-ShiftÔºåÂÆûÁé∞‰∫ÜÊõ¥È´òÁöÑÁÅµÊ¥ªÊÄßÂíåÁ≤æÁ°ÆÂ∫¶Ôºå‰ΩøÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞Â§ÑÁêÜÂíåËûçÂêàÊó∂Èó¥Ê≠•‰πãÈó¥ÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´ò‰∫ÜÊï¥‰ΩìÊÄßËÉΩ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3869854a-a4e3-4652-9698-b0d81bbbd645",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RWKV_RNN(MyModule):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.eval() # set torch to inference mode\n",
    "        \n",
    "        w = torch.load(args.MODEL_NAME + '.pth', map_location='cpu')\n",
    "\n",
    "        for k in w.keys():\n",
    "            w[k] = w[k].float() # convert to f32 type\n",
    "            if      '.time_' in k: w[k] = w[k].squeeze()\n",
    "            if '.time_faaaa' in k: w[k] = w[k].unsqueeze(-1)\n",
    "\n",
    "        self.n_head = w['blocks.0.att.time_faaaa'].shape[0]\n",
    "        self.head_size = w['blocks.0.ln1.weight'].shape[0] // self.n_head\n",
    "        \n",
    "        self.w = types.SimpleNamespace() # set self.w from w\n",
    "        self.w.blocks = {}\n",
    "        for k in w.keys(): # example: \"blocks.0.att.time_first\" => self.w.blocks[0].att.time_first\n",
    "            parts = k.split('.')\n",
    "            last = parts.pop()\n",
    "            here = self.w\n",
    "            for p in parts:\n",
    "                if p.isdigit():\n",
    "                    p = int(p)\n",
    "                    if p not in here: here[p] = types.SimpleNamespace()\n",
    "                    here = here[p]\n",
    "                else:\n",
    "                    if not hasattr(here, p): setattr(here, p, types.SimpleNamespace())\n",
    "                    here = getattr(here, p)\n",
    "            setattr(here, last, w[k])\n",
    "\n",
    "    def layer_norm(self, x, w):\n",
    "        return F.layer_norm(x, (self.args.n_embd,), weight=w.weight, bias=w.bias)\n",
    "\n",
    "    @MyFunction\n",
    "    def channel_mixing(self, x, state, i:int, time_maa_k, time_maa_r, kw, vw, rw):\n",
    "        i0 = (2+self.head_size)*i+0\n",
    "        sx = state[i0] - x\n",
    "        xk = x + sx * time_maa_k\n",
    "        xr = x + sx * time_maa_r\n",
    "        state[i0] = x\n",
    "        r = torch.sigmoid(rw @ xr)\n",
    "        k = torch.square(torch.relu(kw @ xk)) # square relu, primer paper\n",
    "        return r * (vw @ k)\n",
    "\n",
    "    @MyFunction\n",
    "    def time_mixing(self, x, state, i:int, x_maa, w_maa, k_maa, v_maa, r_maa, g_maa, tm_w1, tm_w2, td_w1, td_w2, time_first, time_decay, kw, vw, rw, gw, ow, ln_w, ln_b):\n",
    "        H = self.n_head\n",
    "        S = self.head_size\n",
    "\n",
    "        i1 = (2+S)*i+1\n",
    "        sx = state[i1] - x\n",
    "        state[i1] = x\n",
    "        xxx = x + sx * x_maa\n",
    "        xxx = torch.tanh(xxx @ tm_w1).view(5, 1, -1)\n",
    "        xxx = torch.bmm(xxx, tm_w2).view(5, -1)\n",
    "        mw, mk, mv, mr, mg = xxx.unbind(dim=0)\n",
    "\n",
    "        xw = x + sx * (w_maa + mw)\n",
    "        xk = x + sx * (k_maa + mk)\n",
    "        xv = x + sx * (v_maa + mv)\n",
    "        xr = x + sx * (r_maa + mr)\n",
    "        xg = x + sx * (g_maa + mg)\n",
    "\n",
    "        w = (time_decay + (torch.tanh(xw @ td_w1) @ td_w2).float()).view(H, S, 1)\n",
    "        w = torch.exp(-torch.exp(w.float()))\n",
    "\n",
    "        r = (rw @ xr).view(H, 1, S)\n",
    "        k = (kw @ xk).view(H, S, 1)\n",
    "        v = (vw @ xv).view(H, 1, S)\n",
    "        g = F.silu(gw @ xg)\n",
    "\n",
    "        s = state[(2+S)*i+2:(2+S)*(i+1), :].reshape(H, S, S)\n",
    "\n",
    "        x = torch.zeros(H, S)\n",
    "        a = k @ v\n",
    "        x = r @ (time_first * a + s)\n",
    "        s = a + w * s\n",
    "    \n",
    "        state[(2+S)*i+2:(2+S)*(i+1), :] = s.reshape(S, -1)\n",
    "        x = x.flatten()\n",
    "\n",
    "        x = F.group_norm(x.unsqueeze(0), num_groups=H, weight=ln_w, bias=ln_b, eps = 64e-5).squeeze(0) * g # same as gn(x/8, eps=1e-5)\n",
    "        return ow @ x\n",
    "\n",
    "    def forward(self, token, state):\n",
    "        with torch.no_grad():\n",
    "            if state == None:\n",
    "                state = torch.zeros(self.args.n_layer * (2+self.head_size), self.args.n_embd)\n",
    "            \n",
    "            x = self.w.emb.weight[token]\n",
    "            x = self.layer_norm(x, self.w.blocks[0].ln0)\n",
    "            for i in range(self.args.n_layer):\n",
    "                att = self.w.blocks[i].att\n",
    "                x = x + self.time_mixing(self.layer_norm(x, self.w.blocks[i].ln1), state, i,\n",
    "                    att.time_maa_x, att.time_maa_w, att.time_maa_k, att.time_maa_v, att.time_maa_r, att.time_maa_g, att.time_maa_w1, att.time_maa_w2,\n",
    "                    att.time_decay_w1, att.time_decay_w2, att.time_faaaa, att.time_decay,\n",
    "                    att.key.weight, att.value.weight, att.receptance.weight, att.gate.weight, att.output.weight,\n",
    "                    att.ln_x.weight, att.ln_x.bias)\n",
    "                ffn = self.w.blocks[i].ffn\n",
    "                x = x + self.channel_mixing(self.layer_norm(x, self.w.blocks[i].ln2), state, i, \n",
    "                    ffn.time_maa_k, ffn.time_maa_r, \n",
    "                    ffn.key.weight, ffn.value.weight, ffn.receptance.weight)\n",
    "            \n",
    "            x = self.w.head.weight @ self.layer_norm(x, self.w.ln_out)\n",
    "            return x.float(), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5235be83-a574-41f6-8546-bc415e2aeacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using CPU. Loading /data1/ckw/RWKV-x060-World-1B6-v2.1-20240328-ctx4096 ...\n",
      "\n",
      "Preprocessing context (slow version. see v2/rwkv/model.py for fast version)\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nUsing CPU. Loading {args.MODEL_NAME} ...')\n",
    "model = RWKV_RNN(args)\n",
    "\n",
    "print(f'\\nPreprocessing context (slow version. see v2/rwkv/model.py for fast version)')\n",
    "init_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "035ce374-c1c0-43b8-9ba9-37df297baae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in tokenizer.encode(context):\n",
    "    init_out, init_state = model.forward(token, init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e17d6ef-c02c-4d27-8cf6-9a262f75f77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--[ Trial 0 ]----------------- \n",
      "Datawhale is ‚û°Ô∏è‚ÄºÔ∏è\n",
      "https://twitter.com/datawhale_cn/status/1463997087819689985\n",
      "#Data #AI #DataAnalytics #AIOps #DataOps #MachineLearning #DataScience #DataLakeAnalytics #Hadoop #Amazon #Google #AWS #Azure #Dataprep #DevOps #OSS #Linux #Unix #BigData #BigDataOps #DataArchitecture #DataScienceOps #MachineLearningOps\n",
      "\n",
      "--[ Trial 1 ]----------------- \n",
      "Datawhale is ü§ì\n",
      "\n",
      "--[ Trial 2 ]----------------- \n",
      "Datawhale is ü§Ø. They have a solid team, a really good SaaS product and the tools to support their users. That said, I have to take a serious look at the privacy and security of their platform before I buy into their story. I think this is a case of big companies buying into the hype, and they're not taking into account all the realities that go into building a privacy-focused product.\n",
      "P.S. You can still apply to Datawhale's Program.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for TRIAL in range(NUM_TRIALS):\n",
    "    print(f'\\n\\n--[ Trial {TRIAL} ]-----------------', context, end=\"\")\n",
    "    all_tokens = []\n",
    "    out_last = 0\n",
    "    out, state = init_out.clone(), init_state.clone()\n",
    "    for i in range(LENGTH_PER_TRIAL):\n",
    "        token = sample_logits(out, TEMPERATURE, TOP_P)\n",
    "        all_tokens += [token]\n",
    "        try:\n",
    "            tmp = tokenizer.decode(all_tokens[out_last:])\n",
    "            if '\\ufffd' not in tmp: # only print when we have a valid utf-8 string\n",
    "                print(tmp, end=\"\", flush=True)\n",
    "                out_last = i + 1\n",
    "        except:\n",
    "            pass\n",
    "        out, state = model.forward(token, state)       \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c33e0-6d5b-4143-b85d-86777a2f5739",
   "metadata": {},
   "source": [
    "v6Âíåv5Áõ∏ÊØîÔºåÊÑüËßâÊõ¥ÂñúÊ¨¢‰ΩøÁî®emoj‰∫ÜÂìàÂìà"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kewei-ai",
   "language": "python",
   "name": "kewei-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
